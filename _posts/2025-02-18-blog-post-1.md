---
title: 'Manual data layout transformation: Packed AoS vs SoA'
date: 2025-02-18
permalink: /posts/2025/02/blog-post-1/
tags:
  - compilers
  - Gibbon compiler
  - data layout transformation 
  - data representation 
  - packed data
---

# Abstract 

The packed data layout representation discussed here is inspired from the Gibbon compiler. The Gibbon compiler generates serialized representations of tree-like recursive data structures and generates traversals over that data by fixing a particular serialization order. The traversals are more efficient because of enhanced spatial locality. The current compiler generates a representation that serializes the data in one big buffer, we term this an AoS representation. An analogue to this would be an SoA representation with separate buffers for different fields.


# Overview to the Gibbon compiler

Gibbon [1] is a tree traversal accelerator that optimizes the performance of tree traversals over tree-like data. The programmer can write programs in a subset of Haskell. This high level code is then lowered to various IRs. The first level of IR involves passes that monomorphize and flatten the control flow of the program among others. The IR is put in ANF form. The second level of IR called LOCAL, has location information throughout the code that's derived from a constraint system to figure out the exact layout of the data types. The third level of the IR removes all the types and uses a Cursor `(char*)` for traversing any data type. The final level of the IR is similar to an imperative language like C. This follows code generation to C. For detailed information check out [1], [2], [3] and [4].

# Introduction

Consider the data type definition of a Cons list in Haskell.

```haskell

  data List = Cons Int (List) | Nil
```

Throughout this blog, we will look at the data representation from the lens of the Haskell Cons list. To visualize the current representation that the Gibbon compiler generates, we can use a 1 byte tag for the Cons tag and an C `int` type for the Integer. We can use a Cursor (`char*` in C) to represent the memory for the List.

The figure below on the left shows a Cons style list in the AoS form. In this form the complete datatype is laid out in one contiguous buffer. On the right, we show the representation of the Cons style list in the SoA form. In the SoA form, the data constructors and integers are in two separate buffers.
![Figure1](/images/AoS_vs_SoA-1.png)

In C the types look like the following.

```c 

  typedef CursorTy char*;
  typedef IntTy int;
  typedef TagTy char;
```

For our simple experiment, we will be allocating one flat big buffer for the AoS memory of the List. This is contrary to what Gibbon does. Gibbon uses chunk allocation to increase the allocated region by a factor of 2 every time. For this experiment we pre-allocate the region for simplicity reasons.

In the AoS representation we have one big buffer, the space we need for the list can be pre-calculated as follows. Since we are using 1 byte for the Cons tag. Each Cons tag takes a total of 5 bytes which includes the `int`. For a list size of 10,000 we need `(10,000 * 5) + 1` bytes in total. This is equal to 50,001 bytes. We need 1 byte for the Nil tag. In C this look as follows:

```c

IntTy listSize = argv[1];
CursorTy region = (CursorTy) malloc(sizeof(char) * ((5 * listSize) + 1));
```

Now let us look at a simple build list function in Haskell and its lowered form in C.

Haskell code: 
```haskell 

buildList :: Int -> List 
buildList len = if len <= 0 
                then Nil 
                else 
                   let rst = buildList (len - 1)
                     in Cons len rst
```

The C counter part looks something like this. We use a CursorTy for the memory of the List. The memory for the List is pointed to by the variable `list`.
We return the start of the region in the variable `listStart` for convention. The Cons tag is represented using the character '0' and the Nil tag is represented by using the character '1'.

Note that the C functions that we will write are tail recursive. There is no work done after the recursive call returns. This allows the compiler to do a optimization called tail call optimization. This eliminates the use of the stack by getting rid of the recursive call in the assembly. The call is replaced by a jump to the start label of the function. This is similar to an iterative loop.

```c 

CursorTy mkList(CursorTy list, int length, CursorTy listStart){
   if (length <= 0){
	//write a Nil.
	*((TagTy*) list) = '1';
	return listStart;
                		
   }
   else {
	*((TagTy*) list) = '0'; 
	CursorTy writeInt = list + 1; 
	*((IntTy*) writeInt) = length; 
	CursorTy writeNext = list + 1 + sizeof(IntTy);
	CursorTy listHead = mkList(writeNext, length - 1,
                                                     listStart);
	return listHead;
	
   }
}
```

In a purely functional style, the same variable is never re-used. The philosophy is to always generate new variables that signify different memory locations.
Unless we are optimizing the runtime, references are not commonplace. However, since we are chasing after the fastest runtime, we want to allow ourselves to mutate the existing region.

The version of the code that writes to a new region rather than mutate the existing region will be called out of place. On the other hand, the version that mutates an existing memory region will be called in place. We will write a recursive version as well an an iterative version of the function for performance comparison. For simplicity, we will write a function that adds 1 to every `Cons` cell in the list. This function will be called `add1`. Thus for the AoS representation, we have 4 variants of the code:

- add1RecusriveInPlace - Recursive version that allows in place updates.

```c

CursorTy add1RecursiveInPlace(CursorTy list, CursorTy listStart){
    TagTy tag = *((TagTy*) list);
    switch (tag){
           case '0' :
	     ;
	     IntTy val = *((IntTy*) (list + 1)); 
	     IntTy val_new = val + 1; 
	     CursorTy listNext = list + 1 + sizeof(IntTy); 
	     *((IntTy*) (list + 1)) = val_new; 
	     return add1RecursiveInPlace(listNext, listStart);
	     break;
	   case '1':
	     ;
	     return listStart;
	     break;
	   default:
	     printf("Error: List was not formed correctly.\n");
	     break;
    }
}
```

- add1RecursiveOutOfPlace - Recursive version that writes to a new memory location.

```c

CursorTy add1RecursiveOutOfPlace(CursorTy list, CursorTy newList,
                                             CursorTy listStart){

    TagTy tag = *((TagTy*) list);
    switch (tag){
        case '0' :
	    ;
	    IntTy val = *((IntTy*) (list + 1)); 
	    IntTy val_new = val + 1; 
	    CursorTy listNext = list + 1 + sizeof(IntTy); 
            *((TagTy*) newList) = '0';
            *((IntTy*) (newList + 1)) = val_new;
	    CursorTy newListNext = newList + 1 + sizeof(IntTy); 
	    return add1RecursiveOutOfPlace(listNext, newListNext,
                                                      listStart);
	    break;
	case '1':
            ;
	    *((TagTy*) newList) = '1';
	    return listStart;
	    break;
	    default:
	    printf("Error: List was not formed correctly.\n");
	    break;
    }
}
```

- add1IterativeInPlace - Iterative version that allows in place updates. In the iterative versions we don't need to return the start address of the new region. We can avoid that by copying the input and output `CursorTy` to new local variables.

```c

void add1IterativeInPlace(CursorTy list){
    CursorTy intCursor = list;
    TagTy tag = *((TagTy*) intCursor);
    while(tag != '1'){
        *((IntTy*) (intCursor + 1)) = *((IntTy*) (intCursor + 1)) 
                                                             + 1;
        intCursor += 1 + sizeof(IntTy); 
	tag = *((TagTy*) intCursor);
    }
}
```

- add1IterativeOutOfPlace - Iterative version that writes to a new memory location.

```c

void add1IterativeOutOfPlace(CursorTy list, CursorTy listOut){
    CursorTy inCursor = list;
    CursorTy outCursor = listOut;
    TagTy tag = *((TagTy*) inCursor);

    while(tag != '1'){
       *((TagTy*) outCursor) = tag;
       inCursor += 1;
       outCursor += 1;	
       *((IntTy*) outCursor) = *((IntTy*) inCursor) + 1;
       inCursor += sizeof(IntTy);
       outCursor += sizeof(IntTy);
       tag = *((TagTy*) inCursor);
    }

    //write the last tag;
    *((TagTy*) outCursor) = tag;
}
```

The SoA representation of the list requires a struct to hold the actual list. Because we have a pointer to multiple buffers. One example of such a structure could look like the following:

```c

typedef struct {
  CursorTy tagRegion;
  CursorTy k1;
} Cons1FieldList;
```

In the struct `Cons1FieldList`, we have a cursor for the tags (tagRegion) and another for the integers (k1). In C, the corresponding build function would look like the following.

```c

Cons1FieldList* mkList(Cons1FieldList *inList, IntTy listLength, Cons1FieldList *startAddress){
   if (listLength <= 0){
       *((TagTy*) inList->tagRegion) = '1';
       return startAddress;
   }
   else{
       *((TagTy*) inList->tagRegion) = '0';
       inList->tagRegion = inList->tagRegion + sizeof(TagTy);
       *((IntTy*) inList->k1) = listLength;
       inList->k1 = inList->k1 + sizeof(IntTy);
       Cons1FieldList *returnedList = mkList(inList, listLength - 1, startAddress);
       return returnedList;
   }
}
```

There are 4 variants similar to the AoS representation. These are add1RecusriveInPlace, add1RecursiveOutOfPlace, add1IterativeInPlace, add1IterativeOutOfPlace. In addition, there is an optimized iterative version that uses a for loop. This also comes in two variants, the in place version that mutates the list in place and the out of place version that copies the list to a new location. Though, the variant of particular interest is the optimized in place version. With the in place version in the SoA form, we just need to traverse the integer buffer since we know `add1` does not have any dependencies across iterations. This does two important things. For one, it allows us to skip one buffer, that is, the data constructor buffer. Secondly, it allows us to vectorize the for loop over the integer buffer. As we will see, the compiler can do a really good job at auto-vectorization. Thanks to the simple structure of the for loop. Now we show the code of all the SoA variants.

- add1RecursiveInPlace

```c

Cons1FieldList *add1RecursiveInPlace(Cons1FieldList *inRegion, Cons1FieldList *startAddress){
   TagTy tag = *((TagTy*) inRegion->tagRegion);
   inRegion->tagRegion += 1;
   switch(tag){
           case '0':
                   ;
                   *((IntTy*) inRegion->k1) = *((IntTy*) inRegion->k1) + 1;
                   inRegion->k1 += sizeof(IntTy);
                   return add1RecursiveInPlace(inRegion, startAddress);
                   break;
           case '1':
                   ;
                   return startAddress;
                   break;
           default:
                  ;
                  break;
   }
}
```

- add1RecursiveOutOfPlace

```c

Cons1FieldList *add1RecursiveOutOfPlace(Cons1FieldList *inRegion, Cons1FieldList *newRegion, Cons1FieldList *startAddress){
   TagTy tag = *((TagTy*) inRegion->tagRegion);
   inRegion->tagRegion += 1;
   *((TagTy*) newRegion->tagRegion) = tag;
   newRegion->tagRegion += 1;
   switch(tag){
           case '0':
                   ;
                   IntTy val1 = *((IntTy*) inRegion->k1);
                   inRegion->k1 += sizeof(IntTy);
                   *((IntTy*) newRegion->k1) = val1 + 1;
                   newRegion->k1 += sizeof(IntTy);
                   return add1RecursiveOutOfPlace(inRegion, newRegion, startAddress);
                   break;
           case '1':
                   ;
                   return startAddress;
                   break;
           default:
                  ;
                  break;
   }
}
```
- add1IterativeInPlace

```c

void add1IterativeInPlace(Cons1FieldList *inRegion){
   TagTy tag = *((TagTy*) inRegion->tagRegion);
   CursorTy tagCursor = inRegion->tagRegion;
   CursorTy k1 = inRegion->k1;
   while(tag != '1'){
       *((IntTy*) k1) += 1;
       k1 += sizeof(IntTy);
       tagCursor += 1;
       tag = *((TagTy*) tagCursor);
   }
}
```

- add1IterativeOutOfPlace

```c

void add1IterativeOptOutOfPlace(Cons1FieldList *inRegion, Cons1FieldList *outRegion, IntTy listSize){
   CursorTy dataConBuffer = inRegion->tagRegion;
   CursorTy dataConBufferOut = outRegion->tagRegion;
   for (int i = 0; i < listSize; i++){
           *((TagTy*) dataConBufferOut) = *((TagTy*) dataConBuffer);
           dataConBuffer += 1;
           dataConBufferOut += 1;
}
   CursorTy kIn1 = inRegion->k1;
   CursorTy kOut1 = outRegion->k1;
   for (int i = 0; i < listSize; i++){
           *((IntTy*) kOut1) = *((IntTy*) kIn1) + 1;
           kIn1 += sizeof(IntTy);
           kOut1 += sizeof(IntTy);
   }
}
```

- add1IterativeOptInPlace

```c

void add1IterativeOptInPlace(Cons1FieldList *inRegion, IntTy listSize){
   CursorTy k1 = inRegion->k1;
   for (int i = 0; i < listSize; i++){
           *((IntTy*) k1) = *((IntTy*) k1) + 1;
           k1 += sizeof(IntTy);
   }
}
```

- add1IterativeOptOutOfPlace

```c

void add1IterativeOptOutOfPlace(Cons1FieldList *inRegion, Cons1FieldList *outRegion, IntTy listSize){
   CursorTy dataConBuffer = inRegion->tagRegion;
   CursorTy dataConBufferOut = outRegion->tagRegion;
   for (int i = 0; i < listSize; i++){
           *((TagTy*) dataConBufferOut) = *((TagTy*) dataConBuffer);
           dataConBuffer += 1;
           dataConBufferOut += 1;
}
   CursorTy kIn1 = inRegion->k1;
   CursorTy kOut1 = outRegion->k1;
   for (int i = 0; i < listSize; i++){
           *((IntTy*) kOut1) = *((IntTy*) kIn1) + 1;
           kIn1 += sizeof(IntTy);
           kOut1 += sizeof(IntTy);
   }
}
```

# Experimental setup 
The following table shows the performance figures of all functions in the AoS representation.

<!-- This functionality was created with help from Microsoft co-pilot -->
<div style="overflow-x: auto; width: auto; border: 1px solid #ddd; padding: 10px; position: relative;">
  <img id="zoom-image" src="/images/300mil_aos_gcc_clang.png" alt="Figure2" style="width: 100%; min-width: 1200px; transition: transform 0.2s;"/>
</div>

<style>
  #zoom-image {
    transition: transform 0.2s, left 0.2s, top 0.2s;
    position: relative;
  }
  #zoom-image:hover {
    transform: scale(2);
  }
</style>

<script>
  document.addEventListener('DOMContentLoaded', function () {
    const img = document.getElementById('zoom-image');
    const container = img.parentElement;

    container.addEventListener('mousemove', function (e) {
      const rect = container.getBoundingClientRect();
      const x = e.clientX - rect.left;
      const y = e.clientY - rect.top;
      const xPercent = x / rect.width * 100;
      const yPercent = y / rect.height * 100;

      img.style.transformOrigin = `${xPercent}% ${yPercent}%`;
    });
  });
</script>

The results here are predictable. The recursive versions perform similar to the iterative versions. This is because the compiler can do a good job at tail call optimizing the tail recursive call and they are in the correct structural form.

The in place versions are faster than their out of place versions. They have fewer total instructions and take lesser cycles. The in place versions also show lower L2 and L3 cache misses. The out of place versions have more store instructions. This is because the out of place versions have to copy unused data to the output buffer. In this 1 field `Cons` list example, we still have to copy the data constructors in the output buffer which increases the store instructions which can be seen in the table. In addition, we have to bump the cursor for the output buffer as well. This will add more arithmetic instructions. We can also see that the L2 load and store misses have increased in the out of place versions.

The following table shows the performance figures of all the functions in the SoA representation.

<!-- This functionality was created with help from Microsoft co-pilot -->
<div style="overflow-x: auto; width: auto; border: 1px solid #ddd; padding: 10px; position: relative;">
  <img id="zoom-image2" src="/images/300mil_soa_gcc_clang.png" alt="Figure3" style="width: 100%; min-width: 1200px; transition: transform 0.2s;"/>
</div>

<style>
  #zoom-image2 {
    transition: transform 0.2s, left 0.2s, top 0.2s;
    position: relative;
  }
  #zoom-image2:hover {
    transform: scale(2);
  }
</style>

<script>
  document.addEventListener('DOMContentLoaded', function () {
    const img = document.getElementById('zoom-image2');
    const container = img.parentElement;

    container.addEventListener('mousemove', function (e) {
      const rect = container.getBoundingClientRect();
      const x = e.clientX - rect.left;
      const y = e.clientY - rect.top;
      const xPercent = x / rect.width * 100;
      const yPercent = y / rect.height * 100;

      img.style.transformOrigin = `${xPercent}% ${yPercent}%`;
    });
  });
</script>

The first thing to notice is that Clang is mostly better than GCC at generating fewer instructions and getting a lower runtime. This may be because clang is doing a better job at instruction scheduling. Most of the results are predictable, the performance of the Recursive and iterative versions are similar thanks to tail call optimization. However, for add1RecursiveOutOfPlace GCC generates in-efficient code compared to the iterative version whereas Clang performance similar to the iterative version. The optimized `add1` in place versions are faster than the non optimized ones. They have much fewer instructions thanks to vectorization. All the versions were compiled with O3. However, for the optimized version of `add1`, we have a standalone O3 version, a version that switches vectorization off and another version that uses 8 lane vectorization. Note that O3 does a 4 lane vectorization by default. The fastest performance for `add1` is from the in place optimized version that uses 8 lane vectorization. This is because it does not have to copy extra data and traverses lesser data. The for loop allows efficient vectorization. The iterative versions that use a while loop utilize vectorization but it is lesser aggressive than the for loop version.

One big outlier in this table is the performance of add1RecursiveOutOfPlace for the GCC version. Its runtime is more than Clang. It generates more instructions and takes more cycles to complete. A closer look at the assembly reveals that GCC schedules the instructions differently than clang. Since x86 assembly instructions are CISC instructions, the scheduling difference may mean that the microop may have to generate more instructions for the GCC version. The difference in instruction scheduling seems to have increased the number of load and store instructions compared to clang by almost 3x. This means that Clang's instruction scheduling may lead to a better memory optimization which requires fewer loads and stores. The CNIC (cycles no instruction was completed) is also twice for GCC which suggests that the code generated by GCC may be having more pipeline stalls due to the scheduling choices. Although, the assembly code looks mostly similar there are some minor differences in instructions and layout. The GCC code uses `add` instead of `inc` in Clang. It also uses a different jump instruction. This may have an impact on locality and pipe-lining. Since the microop is a blackbox it is hard to tell what instructions were actually executed.

The following is the GCC generated assembly for add1RecursiveOutOfPlace

```asm 

0000000000001770 <add1RecursiveOutOfPlace>:
    1770:	48 89 d0             	mov    %rdx,%rax
    1773:	66 66 66 66 2e 0f 1f 	data16 data16 data16 cs nopw 0x0(%rax,%rax,1)
    177a:	84 00 00 00 00 00 
    1780:	48 8b 0f             	mov    (%rdi),%rcx
    1783:	0f b6 11             	movzbl (%rcx),%edx
    1786:	48 ff c1             	inc    %rcx
    1789:	48 89 0f             	mov    %rcx,(%rdi)
    178c:	48 8b 0e             	mov    (%rsi),%rcx
    178f:	88 11                	mov    %dl,(%rcx)
    1791:	48 ff 06             	incq   (%rsi)
    1794:	80 fa 30             	cmp    $0x30,%dl
    1797:	75 20                	jne    17b9 <add1RecursiveOutOfPlace+0x49>
    1799:	48 8b 4f 08          	mov    0x8(%rdi),%rcx
    179d:	8b 11                	mov    (%rcx),%edx
    179f:	48 83 c1 04          	add    $0x4,%rcx
    17a3:	48 89 4f 08          	mov    %rcx,0x8(%rdi)
    17a7:	ff c2                	inc    %edx
    17a9:	48 8b 4e 08          	mov    0x8(%rsi),%rcx
    17ad:	89 11                	mov    %edx,(%rcx)
    17af:	48 83 c1 04          	add    $0x4,%rcx
    17b3:	48 89 4e 08          	mov    %rcx,0x8(%rsi)
    17b7:	eb c7                	jmp    1780 <add1RecursiveOutOfPlace+0x10>
    17b9:	c3                   	ret    
    17ba:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
```

The following is the Clang generated assembly for add1RecursiveOutOfPlace

```asm 

0000000000401b70 <add1RecursiveOutOfPlace>:
  401b70:	48 89 d0             	mov    %rdx,%rax
  401b73:	48 8b 0f             	mov    (%rdi),%rcx
  401b76:	0f b6 11             	movzbl (%rcx),%edx
  401b79:	48 83 c1 01          	add    $0x1,%rcx
  401b7d:	48 89 0f             	mov    %rcx,(%rdi)
  401b80:	48 8b 0e             	mov    (%rsi),%rcx
  401b83:	88 11                	mov    %dl,(%rcx)
  401b85:	48 83 06 01          	addq   $0x1,(%rsi)
  401b89:	80 fa 30             	cmp    $0x30,%dl
  401b8c:	74 02                	je     401b90 <add1RecursiveOutOfPlace+0x20>
  401b8e:	c3                   	ret    
  401b8f:	90                   	nop
  401b90:	48 8b 57 08          	mov    0x8(%rdi),%rdx
  401b94:	8b 0a                	mov    (%rdx),%ecx
  401b96:	48 83 c2 04          	add    $0x4,%rdx
  401b9a:	48 89 57 08          	mov    %rdx,0x8(%rdi)
  401b9e:	48 8b 56 08          	mov    0x8(%rsi),%rdx
  401ba2:	83 c1 01             	add    $0x1,%ecx
  401ba5:	89 0a                	mov    %ecx,(%rdx)
  401ba7:	48 83 c2 04          	add    $0x4,%rdx
  401bab:	48 89 56 08          	mov    %rdx,0x8(%rsi)
  401baf:	eb c2                	jmp    401b73 <add1RecursiveOutOfPlace+0x3>
  401bb1:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
  401bb8:	00 00 00 00 
  401bbc:	0f 1f 40 00          	nopl   0x0(%rax)
```
When we compare the performance of AoS vs SoA we see that the same AoS versions perform better than the SoA versions. This is because AoS versions have to execute slightly lesser instructions. They exhibit lower L2 and L3 cache misses since they only have to manage 1 allocated buffer. However, we cannot generate the for loop using optimized in place version in the AoS representation because the data constructors and integers are interleaved. This creates two problems. One is that we cannot skip unused fields and second is that we cannot do efficient vectorization. Note that to skip fields, we have to use in place versions of the SoA layout. In the out of place versions we still have to copy the unused fields. The `add1` optimized in place version exploits both these opportunities and is indeed the fastest.

# Comparison of AoS vs SoA when number of unused fields increase







[1]: https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECOOP.2017.26

[2]: http://recurial.com/pldi19main.pdf

[3]: https://iu-parfunc.github.io/gibbon/public/icfp21.pdf

[4]: https://drops.dagstuhl.de/storage/00lipics/lipics-vol313-ecoop2024/LIPIcs.ECOOP.2024.38/LIPIcs.ECOOP.2024.38.pdf